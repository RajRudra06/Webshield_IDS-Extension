import onnx
from onnx_tf.backend import prepare
import tensorflowjs as tfjs

print("ğŸ”„ Starting ONNX â†’ TensorFlow.js conversion...")

# Step 1: Load your ONNX model
print("ğŸ“‚ Loading ONNX model...")
onnx_model = onnx.load("lightGBMClassifier.onnx")
print("âœ… ONNX model loaded")

# Step 2: Convert ONNX to TensorFlow
print("ğŸ”„ Converting to TensorFlow...")
tf_rep = prepare(onnx_model)
print("âœ… Converted to TensorFlow")

# Step 3: Export as TensorFlow SavedModel
print("ğŸ’¾ Exporting TensorFlow model...")
tf_rep.export_graph("tf_model")
print("âœ… TensorFlow model exported")

# Step 4: Convert to TensorFlow.js
print("ğŸ”„ Converting to TensorFlow.js...")
tfjs.converters.convert_tf_saved_model(
    "tf_model",
    "tfjs_model"
)
print("âœ… TensorFlow.js model created")

print("\nğŸ‰ Conversion complete!")
print("ğŸ“ Output folder: tfjs_model/")
print("   Files created:")
print("   â”œâ”€â”€ model.json")
print("   â””â”€â”€ group1-shard1of1.bin (or similar .bin file)")

